{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q feast==0.52.0 pandas==2.2.2 numpy==2.0.2 scikit-learn==1.6.1"
      ],
      "metadata": {
        "id": "uw10Jz5EXITc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "B5869BH3JyRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone, timedelta\n",
        "\n",
        "from feast import FeatureStore, Entity, Field, FileSource, FeatureView, FeatureService\n",
        "from feast.types import Int64, Float32\n",
        "from feast.value_type import ValueType\n",
        "\n",
        "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "OMmUiPOobqwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feast Repo Setup"
      ],
      "metadata": {
        "id": "RCyi_mvEJ08t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REPO_DIR = Path(\"feast_telco_repo\").absolute()\n",
        "if REPO_DIR.exists():\n",
        "    shutil.rmtree(REPO_DIR)\n",
        "(REPO_DIR / \"data\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "(REPO_DIR / \"feature_store.yaml\").write_text(f\"\"\"\n",
        "project: telco_churn\n",
        "registry: {REPO_DIR / \"registry.db\"}\n",
        "provider: local\n",
        "offline_store:\n",
        "  type: file\n",
        "online_store:\n",
        "  type: sqlite\n",
        "  path: {REPO_DIR / \"online_store.db\"}\n",
        "entity_key_serialization_version: 3\n",
        "\"\"\".strip()+\"\\n\")"
      ],
      "metadata": {
        "id": "JmQtNupsbqjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch and Clean Dataset"
      ],
      "metadata": {
        "id": "HmE_DBv0J7Iz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://raw.githubusercontent.com/aiplanethub/Datasets/master/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
        "df = pd.read_csv(URL).rename(columns={\"customerID\": \"customer_id\"}).copy()\n",
        "\n",
        "# Convert numeric\n",
        "df[\"TotalCharges\"]   = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
        "df[\"MonthlyCharges\"] = pd.to_numeric(df[\"MonthlyCharges\"], errors=\"coerce\")\n",
        "df[\"tenure\"]         = pd.to_numeric(df[\"tenure\"], errors=\"coerce\")\n",
        "\n",
        "# Drop NA criticals\n",
        "df = df.dropna(subset=[\"customer_id\", \"tenure\", \"MonthlyCharges\", \"TotalCharges\", \"Churn\"])\n",
        "\n",
        "# Binary label\n",
        "df[\"label\"] = (df[\"Churn\"].astype(str).str.strip().str.lower() == \"yes\").astype(int)"
      ],
      "metadata": {
        "id": "YWJR7IMzQetg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = [\n",
        "    \"gender\", \"SeniorCitizen\", \"Partner\", \"Dependents\", \"PhoneService\", \"MultipleLines\",\n",
        "    \"InternetService\", \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\", \"TechSupport\",\n",
        "    \"StreamingTV\", \"StreamingMovies\", \"Contract\", \"PaperlessBilling\", \"PaymentMethod\"\n",
        "]\n",
        "numerical_features = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
        "all_features = numerical_features + categorical_features"
      ],
      "metadata": {
        "id": "xjdJARNhcbmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simulate Feature & Label Timestamps"
      ],
      "metadata": {
        "id": "DhSDZ2muKFda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HORIZON_DAYS = 30\n",
        "rng_end = datetime.now(timezone.utc)\n",
        "rng_start = rng_end - timedelta(days=150)  # room for horizon\n",
        "feat_span_sec = (rng_end - timedelta(days=HORIZON_DAYS) - rng_start).total_seconds()\n",
        "\n",
        "np.random.seed(42)\n",
        "df[\"feature_ts\"] = [rng_start + timedelta(seconds=int(np.random.rand() * feat_span_sec)) for _ in range(len(df))]\n",
        "df[\"label_ts\"]   = df[\"feature_ts\"] + timedelta(days=HORIZON_DAYS)\n",
        "df[\"created_at\"] = df[\"feature_ts\"] + timedelta(minutes=5)  # ingestion lag"
      ],
      "metadata": {
        "id": "J2XUutB6cfiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encode Data for Feast Storage"
      ],
      "metadata": {
        "id": "rMn5Gnm0KM8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_feast = df.copy()\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    df_feast[col] = le.fit_transform(df_feast[col].astype(str))"
      ],
      "metadata": {
        "id": "hOT_MzbbCO2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Feature + Label Datasets"
      ],
      "metadata": {
        "id": "F9WH8WcMKcPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_path = REPO_DIR / \"data\" / \"telco_features.parquet\"\n",
        "entity_label_path = REPO_DIR / \"data\" / \"entity_labels.parquet\"\n",
        "\n",
        "df_feast[[\"customer_id\", *all_features, \"feature_ts\", \"created_at\"]].rename(\n",
        "    columns={\"feature_ts\": \"event_timestamp\"}\n",
        ").to_parquet(features_path, index=False)\n",
        "\n",
        "df[[\"customer_id\", \"label_ts\", \"label\"]].rename(\n",
        "    columns={\"label_ts\": \"event_timestamp\"}\n",
        ").to_parquet(entity_label_path, index=False)"
      ],
      "metadata": {
        "id": "RSai4zSWcnBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Feast Entity, Source, and FeatureView"
      ],
      "metadata": {
        "id": "URsRWhI6KfN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer = Entity(\n",
        "    name=\"customer_id\",\n",
        "    join_keys=[\"customer_id\"],\n",
        "    value_type=ValueType.STRING,\n",
        ")\n",
        "\n",
        "source = FileSource(\n",
        "    path=str(features_path),\n",
        "    timestamp_field=\"event_timestamp\",\n",
        "    created_timestamp_column=\"created_at\",  # guards against late/backfilled data\n",
        ")\n",
        "\n",
        "# Use Float32 for numeric features, Int64 for encoded categoricals\n",
        "schema = [\n",
        "    Field(name=col, dtype=(Float32 if col in numerical_features else Int64))\n",
        "    for col in all_features\n",
        "]\n",
        "\n",
        "customer_stats = FeatureView(\n",
        "    name=\"customer_stats\",\n",
        "    entities=[customer],\n",
        "    ttl=timedelta(days=365),\n",
        "    schema=schema,\n",
        "    source=source,\n",
        "    online=True,\n",
        ")\n",
        "\n",
        "store = FeatureStore(repo_path=str(REPO_DIR))\n",
        "store.apply([customer, customer_stats])"
      ],
      "metadata": {
        "id": "lelLIz-ecqLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieve Point-in-Time Correct Features"
      ],
      "metadata": {
        "id": "S7vEobAiKnTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entity_df = pd.read_parquet(entity_label_path)\n",
        "training_df = store.get_historical_features(\n",
        "    entity_df=entity_df,\n",
        "    features=[f\"customer_stats:{f}\" for f in all_features],\n",
        ").to_df()\n",
        "\n",
        "training_df = training_df.dropna(subset=all_features + [\"label\"])\n",
        "training_df[\"label\"] = training_df[\"label\"].astype(int)"
      ],
      "metadata": {
        "id": "hxateC9Icupw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Time-Based Split (Leakage Safe)"
      ],
      "metadata": {
        "id": "PU4Ybn0BKseB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts = training_df[\"event_timestamp\"]\n",
        "q_train = ts.quantile(0.70)\n",
        "q_val = ts.quantile(0.85)\n",
        "\n",
        "train_df = training_df[ts <= q_train].copy()\n",
        "val_df = training_df[(ts > q_train) & (ts <= q_val)].copy()\n",
        "test_df = training_df[ts > q_val].copy()\n",
        "\n",
        "X_tr, y_tr = train_df[all_features], train_df[\"label\"]\n",
        "X_va, y_va = val_df[all_features], val_df[\"label\"]\n",
        "X_te, y_te = test_df[all_features], test_df[\"label\"]"
      ],
      "metadata": {
        "id": "x9E_vd9rczKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Preprocessing Pipeline"
      ],
      "metadata": {
        "id": "d0tAhKL8KvcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", numeric_pipeline, numerical_features),\n",
        "    (\"cat\", categorical_pipeline, categorical_features)\n",
        "])\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"pre\", preprocessor),\n",
        "    (\"clf\", LogisticRegression(max_iter=5000, class_weight=\"balanced\"))\n",
        "])"
      ],
      "metadata": {
        "id": "jiu6btMFc2cQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.fit(X_tr, y_tr)"
      ],
      "metadata": {
        "id": "rXQGamEJCvWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Threshold Tuning"
      ],
      "metadata": {
        "id": "hN9vyjTjK2el"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob_va = pipeline.predict_proba(X_va)[:, 1]\n",
        "thresholds = np.linspace(0.0, 1.0, 201)\n",
        "best_t, best_f1 = 0.5, -1.0\n",
        "\n",
        "for t in thresholds:\n",
        "    preds = (y_prob_va >= t).astype(int)\n",
        "    f1 = f1_score(y_va, preds, zero_division=0)\n",
        "    if f1 > best_f1:\n",
        "        best_t, best_f1 = t, f1"
      ],
      "metadata": {
        "id": "gq7hgLGRc6ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob_te = pipeline.predict_proba(X_te)[:, 1]\n",
        "y_pred_te = (y_prob_te >= best_t).astype(int)\n",
        "print(f\"\\nChosen threshold (from val): {best_t:.2f}\")\n",
        "print(f\"Test ROC AUC:   {roc_auc_score(y_te, y_prob_te):.4f}\")\n",
        "print(\"\\n=== Test Classification Report ===\")\n",
        "print(classification_report(y_te, y_pred_te, digits=4))"
      ],
      "metadata": {
        "id": "owouqZoXc9RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Materialize to Online Store & Online Feature Lookup (Serving Simulation)"
      ],
      "metadata": {
        "id": "hrDKe-KGK-8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "store.materialize_incremental(end_date=datetime.now(timezone.utc))\n",
        "\n",
        "svc = FeatureService(name=\"customer_stats_service\", features=[customer_stats])\n",
        "store.apply([svc])\n",
        "\n",
        "sample_ids = training_df[\"customer_id\"].drop_duplicates().sample(5, random_state=42).tolist()\n",
        "online = store.get_online_features(\n",
        "    features=svc,\n",
        "    entity_rows=[{\"customer_id\": cid} for cid in sample_ids],\n",
        ").to_dict()\n",
        "\n",
        "print(\"\\n=== Online features sample ===\")\n",
        "for i, cid in enumerate(sample_ids):\n",
        "    row = {k: v[i] for k, v in online.items()}\n",
        "    print(f\"{cid}: {row}\")"
      ],
      "metadata": {
        "id": "ty4P0q0hc_63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wMYWYfkbeM6U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}